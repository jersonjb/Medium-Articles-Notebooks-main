{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune GPT3.5 Turbo Model With Custom Data\n",
        "\n",
        "Zoumana KEITA"
      ],
      "metadata": {
        "id": "qbY_hAaIRMND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "0FGK0CIwRVlS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KVNplIk_NIYI"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip -q install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "bHMOdJfyvfJs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acquire the training data from Hugging Face\n",
        "yahoo_answers_qa = load_dataset(\"yahoo_answers_qa\", split=\"train\")"
      ],
      "metadata": {
        "id": "VnSJ8vmIvq2a"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of the data and its structure\n",
        "yahoo_answers_qa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI9thjlvw43Z",
        "outputId": "176609bf-1127-41f5-ab58-4c7a6a90ba20"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
              "    num_rows: 87362\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i91M2amPvsMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a subset of 500 observations\n",
        "yahoo_answers_qa = yahoo_answers_qa.select(range(500))\n",
        "\n",
        "yahoo_answers_qa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FEOAJj7v45E",
        "outputId": "c8a3d7d9-6b92-4cdb-8c46-e1f9495a259d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
              "    num_rows: 500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yahoo_answers_qa[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv1CsyYZxXOG",
        "outputId": "172abb4a-2f22-4f16-fcfa-3a6091965215"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '2020338',\n",
              " 'question': 'Why did the U.S Invade Iraq ?',\n",
              " 'answer': \"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\",\n",
              " 'nbestanswers': [\"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\",\n",
              "  'Because there is a lot of oil in Iraq.',\n",
              "  'It is tempting to say that the US invaded Iraq because it has lots of oil, but the US is not a country in a deep economic problem that capturing other country’s oil is an actual need for survival. It is more likely that the Iraq invading Kuwait scenario would fall under that assumption.. I think that the US government has come to a conclusion that we are on the verge of a war of religions, or more likely ideologies. It would be presumptuous to try and determent a one cause to the coming war. . I think that the world wide spread of the media with its many forms (Cable, Satellite, Internet, etc.)  have pushed the Moslem regimes to the extreme, fearing that secularity and democratic influence is penetrating their country and will result in an up raising against them. One of the best way to maintain the power that you have and even gain more of it, is by hatred. When the common man is occupied hating an outside enemy, its hatred is kept out side the county and would not be directed towards the regime. . So- I believe that the US understands that the fanatic Moslem regimes have already started a war on the democratic world and now is the time to try a fight it.. . So why invade Iraq? Because it is a huge, week Moslem country that thought to be easy to defeat. . This is exactly the same reason why Afghanistan was first and Syria is next in line.',\n",
              "  'I think Yuval is pretty spot on. It\\'s a proving ground and a focal point for terror activity that\\'s not on American soil. And, because no one liked Saddam Hussein, no other countries (even in the Middle East) were about to rise up and join his side.. . Rabid speculation: now the Pentagon has a model that says it takes ~5 years, ~$200B and ~2,000 casualties to \"rebuild\" a dictatorship into a democracy. Who\\'s next on the list?'],\n",
              " 'main_category': 'News & Events'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format the data for fine-tuning"
      ],
      "metadata": {
        "id": "fJnN3mO-xeoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For fine-tuning, a consistent format is maintained for each pair of questions and answers across the entire training and testing data.  \n",
        "\n",
        "{              \n",
        "  \"messages\": [             \n",
        "    {\"role\": \"system\", \"content\": \"SYSTEM's ROLE\"},           \n",
        "    {\"role\": \"user\", \"content\": \"USER's QUESTION\"},            \n",
        "    {\"role\": \"assistant\", \"content\": \"SYSTEM's RESPONSE\"}\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "SFd0NCxExshg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def format_data(data):\n",
        "\n",
        "  formatted_data = [\n",
        "    {\"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are the Yahoo platform user's assistant. Please reply users' answer using polite and respectful language.\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': message[\"question\"]\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'role': 'assistant',\n",
        "            'content': message[\"answer\"]\n",
        "        }]\n",
        "     } for message in data\n",
        "  ]\n",
        "\n",
        "  random.shuffle(formatted_data)\n",
        "\n",
        "  return formatted_data"
      ],
      "metadata": {
        "id": "OSb5z_yd1HE7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_data = format_data(yahoo_answers_qa)\n",
        "\n",
        "formatted_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1SD7APA1fmF",
        "outputId": "b735a744-e3ab-455e-9bbd-13b3681ef91b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': \"You are the Yahoo platform user's assistant. Please reply users' answer using polite and respectful language.spectful language.\"},\n",
              "  {'role': 'user', 'content': 'How did the planet Pluto get its name?'},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'All the planets were named for Roman Gods. Pluto is named for the Lord of the Underworld because it is the farthest from the sun.'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation Data"
      ],
      "metadata": {
        "id": "o1QfjH8519co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 70% of the overall 500 observation\n",
        "TRAIN_SIZE = 350\n",
        "\n",
        "training_data = formatted_data[:TRAIN_SIZE]\n",
        "validation_data = formatted_data[TRAIN_SIZE:]\n",
        "\n",
        "print(f\"Training Size: {len(training_data)}\")\n",
        "print(f\"Validation Size: {len(validation_data)}\")"
      ],
      "metadata": {
        "id": "I6ZbWswbNRuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc39b75f-4ac3-4de9-faf8-adac7c203b85"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size: 350\n",
            "Validation Size: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the training and validation data"
      ],
      "metadata": {
        "id": "-McvU6ZD3m7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def save_data(dictionary_data, file_name):\n",
        "\n",
        "  with open(file_name, 'w') as outfile:\n",
        "    for entry in dictionary_data:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ],
      "metadata": {
        "id": "lpqKy5n1Ohcv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_data(training_data, \"training_data.jsonl\")\n",
        "save_data(validation_data, \"validation_data.jsonl\")"
      ],
      "metadata": {
        "id": "01Dt_7u54HoG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PJyCbRXOnas",
        "outputId": "c7c29b61-63c7-4d0f-8751-f6578f67bd45"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flagged\n",
            "sample_data\n",
            "training_data.jsonl\n",
            "validation_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Data to OpenAI"
      ],
      "metadata": {
        "id": "5WvtMNwNa9Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip -q install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssk_STygU48B",
        "outputId": "63a088f9-9e1f-4961-f4be-d1ccb8048734"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.5/75.5 kB 2.1 MB/s eta 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import FineTuningJob, ChatCompletion\n",
        "\n",
        "openai.api_key = 'YOUR KEY'"
      ],
      "metadata": {
        "id": "j3wHXgPyO2G_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_fine_tuning_data(data_path):\n",
        "\n",
        "  oploaded_file = openai.File.create(\n",
        "    file=open(data_path, \"rb\"),\n",
        "    purpose='fine-tune'\n",
        "  )\n",
        "\n",
        "  return oploaded_file"
      ],
      "metadata": {
        "id": "sokvjS2Z6hJ9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training data"
      ],
      "metadata": {
        "id": "MS4EWShn7kXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_training_data = upload_fine_tuning_data(\"training_data.jsonl\")\n",
        "uploaded_training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwSnLYRs66z1",
        "outputId": "516e8463-d8d5-4d1f-b22d-2fa430ff5c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-dlXBxJVIhZK1ygaDgze6nzZT at 0x79e113ca43b0> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-dlXBxJVIhZK1ygaDgze6nzZT\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 191790,\n",
              "  \"created_at\": 1692937269,\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_training_id = uploaded_training_data[\"id\"]\n",
        "print(uploaded_training_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eb-oqZ-7Mak",
        "outputId": "12610bd6-4c65-408c-81a4-dc87dde37c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file-dlXBxJVIhZK1ygaDgze6nzZT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation data"
      ],
      "metadata": {
        "id": "wnLtRWR57nKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_validation_data = upload_fine_tuning_data(\"validation_data.jsonl\")\n",
        "uploaded_validation_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ta8v-7_WVV-",
        "outputId": "5c26791d-de74-4214-ceff-ca1d99fa9921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-GZsY8KiXL6Y5OyrOGZMZPQhw at 0x79e0ff7613f0> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-GZsY8KiXL6Y5OyrOGZMZPQhw\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 80063,\n",
              "  \"created_at\": 1692937398,\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_validation_id = uploaded_validation_data[\"id\"]\n",
        "print(uploaded_validation_id)"
      ],
      "metadata": {
        "id": "iEw1aWAjbTrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cd5137-20f6-45f1-83ea-13bce45c7c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file-GZsY8KiXL6Y5OyrOGZMZPQhw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "z11XZRk3bFwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fine_tuning(model_name, train_id, val_id):\n",
        "\n",
        "  fine_tuning_response = FineTuningJob.create(\n",
        "      training_file=train_id,\n",
        "      validation_file=val_id,\n",
        "      model=model_name\n",
        "  )\n",
        "\n",
        "  return fine_tuning_response"
      ],
      "metadata": {
        "id": "toXpW-QfWUeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trigger fine-tuning"
      ],
      "metadata": {
        "id": "kGeb16Kh8e7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "fine_tuning_response = create_fine_tuning(model_name,\n",
        "                                          uploaded_training_id,\n",
        "                                          uploaded_validation_id)\n",
        "\n",
        "print(fine_tuning_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZcpRcPi8hWR",
        "outputId": "84873a71-8da8-4288-c045-3855f4aa5ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-OLaMvZouQ9rlaHw6EYeSzqjh\",\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"created_at\": 1692937704,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-0fNevKdYONDre498IjKAHt12\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"created\",\n",
            "  \"validation_file\": \"file-GZsY8KiXL6Y5OyrOGZMZPQhw\",\n",
            "  \"training_file\": \"file-dlXBxJVIhZK1ygaDgze6nzZT\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 3\n",
            "  },\n",
            "  \"trained_tokens\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning_job_ID = fine_tuning_response['id']\n",
        "\n",
        "print(fine_tuning_job_ID)"
      ],
      "metadata": {
        "id": "DaXK5LNKh19c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2154e8-9bf7-4fad-bf6f-eb303078d454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ftjob-OLaMvZouQ9rlaHw6EYeSzqjh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the state of a fine-tune\n",
        "fine_tuning_response = FineTuningJob.retrieve(fine_tuning_job_ID)\n",
        "fine_tuning_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra2HyQEyhMyg",
        "outputId": "5095b89a-19ff-40f3-8950-a57938f03eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-OLaMvZouQ9rlaHw6EYeSzqjh at 0x79e0fcc1ce50> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-OLaMvZouQ9rlaHw6EYeSzqjh\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1692937704,\n",
              "  \"finished_at\": 1692939142,\n",
              "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7rJ5vdvh\",\n",
              "  \"organization_id\": \"org-0fNevKdYONDre498IjKAHt12\",\n",
              "  \"result_files\": [\n",
              "    \"file-x3B3AIFQdVV0TQ9r6pkPcz8H\"\n",
              "  ],\n",
              "  \"status\": \"succeeded\",\n",
              "  \"validation_file\": \"file-GZsY8KiXL6Y5OyrOGZMZPQhw\",\n",
              "  \"training_file\": \"file-dlXBxJVIhZK1ygaDgze6nzZT\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": 109191\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_ID = fine_tuning_response[\"fine_tuned_model\"]"
      ],
      "metadata": {
        "id": "HnM6VZ6vuMN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing of the Fine Tuned Model"
      ],
      "metadata": {
        "id": "V7xaeR4RcPbO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0kAPt2v3TRL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, model_ID=fine_tuned_model_ID):\n",
        "\n",
        "  message = [\n",
        "              {\n",
        "                  \"role\": \"system\",\n",
        "                  \"content\": \"You are the Yahoo platform user's assistant. Please reply users' answer using polite and respectful language.spectful language.\"\n",
        "              },\n",
        "\n",
        "              {\n",
        "                  \"role\": \"user\",\n",
        "                  \"content\": question\n",
        "              }\n",
        "            ]\n",
        "\n",
        "  # Start inferencing\n",
        "  model_completion = ChatCompletion.create(model=model_ID, messages=message)\n",
        "\n",
        "  # Get the response\n",
        "  response = model_completion.choices[0].message\n",
        "\n",
        "  return response[\"content\"]\n"
      ],
      "metadata": {
        "id": "eaRXuSvM_Aca"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=60)"
      ],
      "metadata": {
        "id": "bCZGPMgFIlmI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Which Internet browser is the best and why?\""
      ],
      "metadata": {
        "id": "NGSjhDCUBnaK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the fine-tuned model"
      ],
      "metadata": {
        "id": "hjgxZ8paBaSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = answer_question(question, model_ID=fine_tuned_model_ID)"
      ],
      "metadata": {
        "id": "TSPxUQMnBiDd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrapper.fill(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1Fyuyy4It_k",
        "outputId": "26404308-50ca-41ed-c567-ddb52230bdf3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All mozillas are good and one good browser of mozilla is\n",
            "netscape. Opera is quite good too and since it is lighter it\n",
            "runs faster.. Mozilla and opera rock!. I have both( 3\n",
            "versions and mozilla separetely)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the GPT3.5 turbo model"
      ],
      "metadata": {
        "id": "wC1I0NBcBcfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = answer_question(question, model_ID=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "_f_NRfB4BX_b"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrapper.fill(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xECLVTJoBX9i",
        "outputId": "68ccc445-f6e0-48f9-dc9e-18775ff7fd7a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best internet browser depends on personal preferences\n",
            "and individual needs. Some popular choices include Google\n",
            "Chrome, Mozilla Firefox, Microsoft Edge, and Safari. Each\n",
            "browser has different features and advantages. It is\n",
            "recommended to try different browsers and see which one fits\n",
            "your requirements in terms of speed, security, user\n",
            "interface, and compatibility with websites and extensions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphical Interface Using Gradio"
      ],
      "metadata": {
        "id": "PXiaPC5pCK8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio"
      ],
      "metadata": {
        "id": "2rJ9w2f5COPv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "7m7TxlvXC3It"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Yahoo Forum User Assistant\"\n",
        "\n",
        "description = (\n",
        "    \"The answer to the question is given based on the chosen model\"\n",
        "    )\n",
        "\n",
        "UI = gr.Interface(\n",
        "    title = title,\n",
        "    description=description,\n",
        "    fn = answer_question,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\"\n",
        ")\n",
        "\n",
        "UI.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "k1CDJHZOCaxU",
        "outputId": "a71ad141-601e-4809-b71f-5eeeebdf2644"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a9ba836cbe6fa8f0ef.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a9ba836cbe6fa8f0ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hq3Hez0SHE3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}