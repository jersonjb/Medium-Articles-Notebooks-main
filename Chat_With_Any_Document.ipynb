{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat With Anything - From PDFs Files to Image Documents: \n",
    "Author: Zoumana KEITA   \n",
    "https://medium.com/@zoumanakeita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRYSu48huSUW",
    "outputId": "6374b7c8-9afc-4999-a31d-c9e980ee8a02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\n",
      "DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\n",
      "WARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\n",
      "DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\n",
      "DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\n",
      "WARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\n",
      "DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\n",
      "DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\n",
      "WARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "pip -q install langchain faiss-cpu unstructured\n",
    "pip -q install openai tiktoken\n",
    "pip -q install pytesseract pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX3ndyD8E9hN"
   },
   "source": [
    "# Chat & Query your PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Document Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filetype import guess\n",
    "\n",
    "def detect_document_type(document_path):\n",
    "    \n",
    "    guess_file = guess(document_path)\n",
    "    file_type = \"\"\n",
    "    image_types = ['jpg', 'jpeg', 'png', 'gif']\n",
    "    \n",
    "    if(guess_file.extension.lower() == \"pdf\"):\n",
    "        file_type = \"pdf\"\n",
    "        \n",
    "    elif(guess_file.extension.lower() in image_types):\n",
    "        file_type = \"image\"\n",
    "        \n",
    "    else:\n",
    "        file_type = \"unkown\"\n",
    "        \n",
    "    return file_type\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Paper Type: pdf\n",
      "Article Information Document Type: image\n"
     ]
    }
   ],
   "source": [
    "research_paper_path = \"./data/transformer_paper.pdf\"\n",
    "article_information_path = \"./data/zoumana_article_information.png\"\n",
    "\n",
    "print(f\"Research Paper Type: {detect_document_type(research_paper_path)}\")\n",
    "print(f\"Article Information Document Type: {detect_document_type(article_information_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Documents Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.image import UnstructuredImageLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "\"\"\"\n",
    "YOU CAN UNCOMMENT THE CODE BELOW TO UNDERSTAND THE LOGIC OF THE FUNCTIONS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \n",
    "    loader = UnstructuredFileLoader(pdf_file)\n",
    "    documents = loader.load()\n",
    "    pdf_pages_content = '\\n'.join(doc.page_content for doc in documents)\n",
    "    \n",
    "    return pdf_pages_content\n",
    "\n",
    "def extract_text_from_image(image_file):\n",
    "\n",
    "    loader = UnstructuredImageLoader(image_file)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    image_content = '\\n'.join(doc.page_content for doc in documents)\n",
    "    \n",
    "    return image_content\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def extract_file_content(file_path):\n",
    "    \n",
    "    file_type = detect_document_type(file_path)\n",
    "    \n",
    "    if(file_type == \"pdf\"):\n",
    "        loader = UnstructuredFileLoader(file_path)\n",
    "        \n",
    "    elif(file_type == \"image\"):\n",
    "        loader = UnstructuredImageLoader(file_path)\n",
    "        \n",
    "    documents = loader.load()\n",
    "    documents_content = '\\n'.join(doc.page_content for doc in documents)\n",
    "    \n",
    "    return documents_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#research_paper_content = extract_text_from_pdf(research_paper_path)\n",
    "#article_information_content = extract_text_from_image(article_information_path)\n",
    "\n",
    "\n",
    "research_paper_content = extract_file_content(research_paper_path)\n",
    "article_information_content = extract_file_content(article_information_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 400 Characters of the Paper: \n",
      "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works.\n",
      "\n",
      "Attention Is All You Need\n",
      "\n",
      "3 2 0 2\n",
      "\n",
      "Ashish Vaswani∗ Google Brain avaswani@google.com\n",
      "\n",
      "Noam Shazeer∗ Google Brain noam@google.com\n",
      "\n",
      "Niki Parmar∗ Google Research nikip@google.com\n",
      "\n",
      "Jakob Uszkoreit∗ Google Research usz@google.com\n",
      "...\n",
      "---------------\n",
      "First 400 Characters of Article Information Document :\n",
      " This document provides a quick summary of some of Zoumana’s article on Medium. It can be considered as the compilation of his 80+ articles about Data Science, Machine Learning and\n",
      "\n",
      "Machine Learning Operations.\n",
      "\n",
      "Whether you are just getting started or you're an experienced professional looking to upskill, these\n",
      "\n",
      "materials can be helpful.\n",
      "\n",
      "Data Science section covers basic to advanced concepts such ...\n"
     ]
    }
   ],
   "source": [
    "nb_characters = 400\n",
    "\n",
    "print(f\"First {nb_characters} Characters of the Paper: \\n{research_paper_content[:nb_characters]}...\")\n",
    "print(\"---\"*5)\n",
    "print(f\"First {nb_characters} Characters of Article Information Document :\\n {article_information_content[:nb_characters]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1140, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Chunks in Research Paper: 51\n",
      "# Chunks in Article Document: 2\n"
     ]
    }
   ],
   "source": [
    "research_paper_chunks = text_splitter.split_text(research_paper_content)\n",
    "article_information_chunks = text_splitter.split_text(article_information_content)\n",
    "\n",
    "print(f\"# Chunks in Research Paper: {len(research_paper_chunks)}\")\n",
    "print(f\"# Chunks in Article Document: {len(article_information_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR KEY>\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def get_doc_search(text_splitter):\n",
    "    \n",
    "    return FAISS.from_texts(text_splitter, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.faiss.FAISS object at 0x141578340>\n"
     ]
    }
   ],
   "source": [
    "doc_search_paper = get_doc_search(research_paper_chunks)\n",
    "print(doc_search_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start chatting with your document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(OpenAI(), chain_type = \"map_rerank\",  \n",
    "                      return_intermediate_steps=True)\n",
    "\n",
    "def chat_with_file(file_path, query):\n",
    "    \n",
    "    file_content = extract_file_content(file_path)\n",
    "    file_splitter = text_splitter.split_text(file_content)\n",
    "    \n",
    "    document_search = get_doc_search(file_splitter)\n",
    "    documents = document_search.similarity_search(query)\n",
    "    \n",
    "    results = chain({\n",
    "                        \"input_documents\":documents, \n",
    "                        \"question\": query\n",
    "                    }, \n",
    "                    return_only_outputs=True)\n",
    "    results = results['intermediate_steps'][0]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chat with the image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/langchain/chains/llm.py:303: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The document is a quick summary of Zoumana’s article on Medium related to Data Science, Machine Learning and Machine Learning Operations. It covers topics such as statistics, model evaluation metrics, SQL queries, NoSQL courses, data visualization, MLOps, and Natural Language Processing. \n",
      "\n",
      "Confidence Score: 100\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the document about\"\n",
    "\n",
    "results = chat_with_file(article_information_path, query)\n",
    "\n",
    "answer = results[\"answer\"]\n",
    "confidence_score = results[\"score\"]\n",
    "\n",
    "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chat with the PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "/usr/local/lib/python3.9/site-packages/langchain/chains/llm.py:303: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Self-attention is used in this document to compute representations of its input and output without using sequence-aligned RNNs or convolution, making the Transformer the first transduction model relying entirely on self-attention.\n",
      "\n",
      "Confidence Score: 100\n"
     ]
    }
   ],
   "source": [
    "query = \"Why is the self-attention approach used in this document?\"\n",
    "\n",
    "results = chat_with_file(research_paper_path, query)\n",
    "\n",
    "answer = results[\"answer\"]\n",
    "confidence_score = results[\"score\"]\n",
    "\n",
    "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!  \n",
    "\n",
    "Made with ❤️ by Zoumana KEITA"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pandas_benchmark",
   "language": "python",
   "name": "pandas_benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
